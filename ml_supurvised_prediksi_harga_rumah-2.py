# -*- coding: utf-8 -*-
"""ML_supurvised_prediksi_harga_rumah.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y2YwXQpGhpKKJF3KZYsdZO0FBedNWPMn

# Library
"""

# -*- coding: utf-8 -*-
"""ML_supurvised_prediksi_harga_rumah_final.ipynb

Automatically generated by Colab.

Original file is located at
    [Link ke Colab Anda jika ada, atau hapus baris ini]
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
# from scipy.stats import pointbiserialr, pearsonr # Tidak digunakan secara aktif di output akhir, tapi ada di kode asli

# --- Konfigurasi Tampilan Pandas dan Plot ---
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)
plt.style.use('seaborn-v0_8-whitegrid') # Menggunakan style plot yang tersedia

"""1. Import Data"""

# Ganti dengan path file Anda jika berbeda
file_path = '/content/DATA RUMAH.xlsx'

try:
    df_raw = pd.read_excel(file_path)
    print("Data berhasil dimuat.")
except FileNotFoundError:
    print(f"File '{file_path}' tidak ditemukan. Harap unggah file atau perbaiki path.")
    print("Menggunakan data dummy untuk melanjutkan...")
    # Data dummy jika file tidak ditemukan (untuk demonstrasi)
    data_dummy = {
        'no': range(1, 51), # Menambah jumlah data dummy
        'nama': [f'Rumah Mewah Tipe {chr(65+(i%7))}{i%3+1}' for i in range(50)],
        'harga': np.random.randint(250000000, 3000000000, 50),
        'luas_tanah': np.random.randint(50, 250, 50),
        'luas_bangunan': np.random.randint(35, 200, 50),
        'kamar_tidur': np.random.randint(1, 6, 50),
        'kamar_mandi': np.random.randint(1, 5, 50),
        'garasi': np.random.randint(0, 4, 50) # Memperluas rentang garasi
    }
    df_raw = pd.DataFrame(data_dummy)

print("\nData Awal (5 baris pertama):")
print(df_raw.head())
print(f"\nInformasi Data Awal:")
df_raw.info()
print(f"\nBentuk DataFrame Awal: {df_raw.shape}")

"""* Data Awal (5 baris pertama):: Ini adalah tampilan awal dari lima baris pertama data Anda. Anda dapat melihat kolom-kolom asli seperti 'NO', 'NAMA RUMAH', 'HARGA', 'LB' (Luas Bangunan), 'LT' (Luas Tanah), 'KT' (Kamar Tidur), 'KM' (Kamar Mandi), dan 'GRS' (Garasi).
* Informasi Data Awal:: Ini adalah ringkasan dari DataFrame Anda.
  * RangeIndex: 1010 entries, 0 to 1009: Menunjukkan ada 1010 baris data, dengan indeks dari 0 hingga 1009.
  * Data columns (total 8 columns):: Menunjukkan ada 8 kolom total.
  * Setiap baris di bawahnya memberikan nama kolom, jumlah nilai non-null (tidak hilang), dan tipe data (Dtype) untuk setiap kolom. Kebanyakan kolom numerik bertipe int64, dan 'NAMA RUMAH' adalah object (biasanya string).
  * memory usage: 63.3+ KB: Ini menunjukkan perkiraan jumlah memori yang digunakan oleh DataFrame.
* Bentuk DataFrame Awal: (1010, 8): Ini mengkonfirmasi dimensi DataFrame Anda: 1010 baris dan 8 kolom.

2. Pra-pemrosesan dan Pembersihan Data
"""

# Membuat salinan untuk pra-pemrosesan
df = df_raw.copy()

# Mengubah nama kolom agar lebih konsisten
df.columns = ['no', 'nama_properti','harga_rp', 'luas_tanah_m2', 'luas_bangunan_m2', 'kamar_tidur', 'kamar_mandi', 'garasi_mobil']
print("\nData setelah rename kolom (5 baris pertama):")
print(df.head())

# Menghapus kolom 'no' (identifier, tidak relevan untuk model)
if 'no' in df.columns:
    df = df.drop('no', axis=1)

# Menghapus kolom 'nama_properti' (membutuhkan NLP lebih lanjut jika ingin diekstrak, untuk saat ini dihapus)
if 'nama_properti' in df.columns:
    df = df.drop('nama_properti', axis=1)

print("\nData setelah menghapus kolom 'no' dan 'nama_properti' (5 baris pertama):")
print(df.head())

# Penanganan Missing Value
print("\nJumlah Missing Value per Kolom Sebelum Penanganan:")
print(df.isna().sum())

# Contoh strategi imputasi (ganti atau sesuaikan jika perlu)
for col in df.select_dtypes(include=np.number).columns:
    if df[col].isna().any():
        df[col] = df[col].fillna(df[col].median()) # Imputasi dengan median untuk numerik

print("\nJumlah Missing Value per Kolom Setelah Penanganan (Median Imputation):")
print(df.isna().sum())

"""* Data setelah rename kolom (5 baris pertama):: Kolom-kolom diubah namanya menjadi format yang lebih konsisten dan mudah dibaca (misalnya, 'HARGA' menjadi 'harga_rp', 'LB' menjadi 'luas_bangunan_m2').
* Data setelah menghapus kolom 'no' dan 'nama_properti' (5 baris pertama):: Kolom 'no' (nomor identifikasi) dan 'nama_properti' (deskripsi teks) dihapus karena tidak relevan untuk model regresi yang akan dibuat. DataFrame sekarang hanya berisi fitur numerik yang akan digunakan untuk prediksi.
* Jumlah Missing Value per Kolom Sebelum Penanganan:: Ini menunjukkan bahwa tidak ada nilai yang hilang (missing values) di kolom manapun pada tahap ini. Semua kolom memiliki 0 missing values.
* Jumlah Missing Value per Kolom Setelah Penanganan (Median Imputation):: Setelah menjalankan kode penanganan missing value (yang mengimputasi dengan median jika ada), hasilnya tetap 0 missing value, menegaskan bahwa data memang sudah bersih dari missing values sejak awal.

3. Eksplorasi Data dan Visualisasi (EDA)
"""

print("\nStatistik Deskriptif Data Bersih:")
print(df.describe())

# Visualisasi Distribusi Fitur Numerik
numerical_features = df.select_dtypes(include=np.number).columns
plt.figure(figsize=(18, 12))
for i, col in enumerate(numerical_features):
    plt.subplot(3, 3, i + 1) # Sesuaikan grid jika jumlah fitur berubah
    sns.histplot(df[col], kde=True, bins=20)
    plt.title(f'Distribusi {col}', fontsize=10)
    plt.xlabel(col, fontsize=8)
    plt.ylabel('Frekuensi', fontsize=8)
plt.tight_layout(pad=2.0)
plt.suptitle('Distribusi Fitur Numerik', fontsize=16, y=1.02)
plt.show()

# Visualisasi Box Plot untuk melihat outlier
plt.figure(figsize=(18, 12))
for i, col in enumerate(numerical_features):
    plt.subplot(3, 3, i + 1)
    sns.boxplot(y=df[col])
    plt.title(f'Box Plot {col}', fontsize=10)
    plt.ylabel(col, fontsize=8)
plt.tight_layout(pad=2.0)
plt.suptitle('Box Plot Fitur Numerik (Identifikasi Outlier)', fontsize=16, y=1.02)
plt.show()

"""* Statistik Deskriptif Data Bersih:: Ini menampilkan ringkasan statistik dasar untuk setiap kolom numerik setelah pembersihan data.
  * count: Jumlah observasi (1010 untuk semua kolom).
  * mean: Rata-rata nilai untuk setiap kolom (misalnya, harga_rp rata-rata sekitar 7.6 miliar Rupiah).
  * std: Standar deviasi, mengukur sebaran data (harga_rp memiliki standar deviasi yang sangat tinggi, menunjukkan variasi harga yang besar).
  * min dan max: Nilai minimum dan maksimum.
  * 25%, 50% (median), 75%: Kuartil, menunjukkan distribusi data (misalnya, 50% rumah memiliki harga di bawah 5 miliar Rupiah).

4. Feature Engineering
"""

# Mengubah harga menjadi satuan juta Rupiah (target variable)
df['harga_juta'] = df['harga_rp'] / 1000000
df = df.drop('harga_rp', axis=1) # Menghapus kolom harga asli

# Membuat fitur kategori berdasarkan kuantil luas tanah
q_luas_tanah = df['luas_tanah_m2'].quantile([0.25, 0.5, 0.75])

def kategorisasi_luas(area, quantiles):
    if area <= quantiles[0.25]:
        return 0 # 'kurang luas'
    elif area <= quantiles[0.50]:
        return 1 # 'sedang'
    else: # area > quantiles[0.50] (karena quantile 0.75 tidak digunakan sebagai batas atas 'sedang')
        return 2 # 'luas'

df['kategori_luas_tanah'] = df['luas_tanah_m2'].apply(lambda x: kategorisasi_luas(x, q_luas_tanah))

# Contoh fitur rasio (opsional, bisa dieksplorasi lebih lanjut)
# df['rasio_bangunan_tanah'] = df['luas_bangunan_m2'] / (df['luas_tanah_m2'] + 1e-6) # +1e-6 untuk menghindari pembagian dengan nol

print("\nData setelah Feature Engineering (5 baris pertama):")
print(df.head())
df.info()

"""* Data setelah Feature Engineering (5 baris pertama):: Ini menunjukkan DataFrame setelah langkah feature engineering.
  * Kolom harga_rp telah diubah menjadi harga_juta (kemungkinan dibagi 1.000.000) dan menjadi target variabel.
  * Kolom baru kategori_luas_tanah telah dibuat, yang mengkategorikan luas tanah ke dalam kelompok-kelompok tertentu (0, 1, 2, dst.).
* Informasi Data:: Menunjukkan bahwa sekarang ada 7 kolom. harga_juta bertipe float64, dan kategori_luas_tanah adalah int64.

5. Seleksi Fitur dan Analisis Korelasi
"""

# Heatmap Korelasi (termasuk target)
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Heatmap Korelasi Antar Fitur (Termasuk Target)', fontsize=14)
plt.show()

# Memisahkan Fitur (X) dan Target (y)
X = df.drop('harga_juta', axis=1)
y = df['harga_juta']

print("\nFitur yang Digunakan (X):")
print(X.columns.tolist())
print("\nTarget (y):")
print(y.name)

"""6. Penskalaan Fitur Numerik"""

# Kolom 'kategori_luas_tanah' sudah berupa ordinal (0, 1, 2), bisa di-scale atau tidak.
# Untuk konsistensi dengan fitur numerik lain, kita akan scale.
numerical_cols_to_scale = X.select_dtypes(include=np.number).columns

scaler = StandardScaler()
X[numerical_cols_to_scale] = scaler.fit_transform(X[numerical_cols_to_scale])

print("\nData Fitur (X) setelah scaling (5 baris pertama):")
print(X.head())

"""* Fitur yang Digunakan (X):: Ini adalah daftar kolom yang akan digunakan sebagai fitur (variabel independen) untuk melatih model.
* Target (y):: Ini adalah kolom yang akan diprediksi oleh model, yaitu harga_juta.
* Data Fitur (X) setelah scaling (5 baris pertama):: Nilai-nilai pada kolom fitur telah di-scale (dinormalisasi). StandardScaler digunakan untuk mengubah data sehingga memiliki rata-rata 0 dan standar deviasi 1. Ini penting untuk beberapa algoritma machine learning agar kinerja model lebih baik.
* Ukuran x_train: (808, 6), x_test: (202, 6): Data telah dibagi menjadi set pelatihan (x_train, y_train) dan set pengujian (x_test, y_test). Set pelatihan berisi 808 sampel dengan 6 fitur, dan set pengujian berisi 202 sampel dengan 6 fitur.
* Ukuran y_train: (808,), y_test: (202,): Ini adalah ukuran untuk variabel target yang sesuai dengan set pelatihan dan pengujian.

7. Pembagian Data (Train & Test)
"""

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"\nUkuran x_train: {x_train.shape}, x_test: {x_test.shape}")
print(f"Ukuran y_train: {y_train.shape}, y_test: {y_test.shape}")

"""8. Pemodelan dengan XGBRegressor dan Penyetelan Hiperparameter"""

print("\nMemulai Penyetelan Hiperparameter XGBoost dengan GridSearchCV...")

# Definisikan model XGBoost
xgb_model = XGBRegressor(random_state=42, objective='reg:squarederror', early_stopping_rounds=10)

# Definisikan grid parameter untuk GridSearchCV
param_grid = {
    'n_estimators': [100, 200, 300],       # Jumlah pohon
    'learning_rate': [0.01, 0.05, 0.1],   # Laju pembelajaran
    'max_depth': [3, 5, 7],               # Kedalaman maksimum pohon
    'colsample_bytree': [0.7, 0.8, 1.0],  # Persentase fitur yang digunakan per pohon
    'subsample': [0.7, 0.8, 1.0],         # Persentase sampel yang digunakan per pohon
}

# Pisahkan sebagian data training untuk validasi pada early stopping di GridSearchCV
x_train_for_grid, x_val_for_grid, y_train_for_grid, y_val_for_grid = train_test_split(
    x_train, y_train, test_size=0.2, random_state=42
)

grid_search = GridSearchCV(estimator=xgb_model,
                           param_grid=param_grid,
                           cv=3,
                           scoring='neg_mean_squared_error',
                           verbose=1,
                           n_jobs=-1)

grid_search.fit(x_train_for_grid, y_train_for_grid,
                eval_set=[(x_val_for_grid, y_val_for_grid)])

print(f"\nParameter Terbaik Ditemukan: {grid_search.best_params_}")
print(f"Skor CV (Negative MSE) Terbaik: {grid_search.best_score_:.4f}")

best_xgboost_model = grid_search.best_estimator_

"""* Memulai Penyetelan Hiperparameter XGBoost dengan GridSearchCV...: Proses ini sedang mencari kombinasi hyperparameter terbaik untuk model XGBoost menggunakan teknik GridSearchCV.
* Fitting 3 folds for each of 243 candidates, totalling 729 fits: Menunjukkan bahwa GridSearchCV mencoba 243 kombinasi hyperparameter yang berbeda, dan untuk setiap kombinasi, model dilatih dan dievaluasi sebanyak 3 kali (3 folds dalam cross-validation), sehingga totalnya ada 729 proses fitting model.
* [0] validation_0-rmse:7025.23249 sampai [99] validation_0-rmse:3188.37273: Ini adalah output dari proses training XGBoost untuk setiap estimator (pohon keputusan) yang ditambahkan. validation_0-rmse menunjukkan Root Mean Squared Error (RMSE) pada set validasi setelah setiap iterasi (penambahan pohon). Angka ini diharapkan menurun seiring berjalannya iterasi, menunjukkan bahwa model belajar dan menjadi lebih baik.
* Parameter Terbaik Ditemukan: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 100, 'subsample': 1.0}: Ini adalah kombinasi hyperparameter terbaik yang ditemukan oleh GridSearchCV yang memberikan kinerja model terbaik berdasarkan metrik yang digunakan (dalam kasus ini, kemungkinan negative mean squared error).
* Skor CV (Negative MSE) Terbaik: -15902225.5805: Ini adalah skor rata-rata cross-validation (dalam bentuk negative mean squared error) yang dicapai oleh model dengan hyperparameter terbaik. Semakin mendekati nol (atau semakin kecil nilai absolutnya untuk MSE negatif), semakin baik.

9. Evaluasi Model Terbaik
"""

# Fungsi untuk evaluasi model
def evaluate_model(model, x_data, y_data, dataset_name=""):
    y_pred = model.predict(x_data)
    r2 = r2_score(y_data, y_pred)
    mae = mean_absolute_error(y_data, y_pred)
    mse = mean_squared_error(y_data, y_pred)
    rmse = np.sqrt(mse)
    print(f"Evaluasi pada {dataset_name}:")
    print(f'  R2 Score: {r2:.4f}')
    print(f'  MAE: {mae:.4f} (juta Rp)')
    print(f'  MSE: {mse:.4f}')
    print(f'  RMSE: {rmse:.4f} (juta Rp)')
    return y_pred

# Evaluasi pada data training
print("\n--- Evaluasi Model pada Data Training ---")
y_pred_train = evaluate_model(best_xgboost_model, x_train, y_train, "Training Set")

# Evaluasi pada data testing
print("\n--- Evaluasi Model pada Data Testing ---")
y_pred_test = evaluate_model(best_xgboost_model, x_test, y_test, "Testing Set")

"""Ini adalah metrik evaluasi model yang dihitung pada data pelatihan dan data pengujian.

* Evaluasi pada Training Set:
  * R2 Score: 0.9492: Menunjukkan bahwa model menjelaskan sekitar 94.92% variabilitas dalam harga rumah pada data pelatihan. Ini adalah skor yang sangat tinggi, menunjukkan fit yang baik pada data yang sudah dilihat model.
  * MAE: 858.7464 (juta Rp): Mean Absolute Error rata-rata selisih absolut antara harga prediksi dan harga aktual adalah sekitar 858.75 juta Rupiah.
  * MSE: 2825151.1453: Mean Squared Error, rata-rata dari kuadrat selisih antara prediksi dan aktual.
  * RMSE: 1680.8186 (juta Rp): Root Mean Squared Error, akar kuadrat dari MSE. Ini adalah rata-rata deviasi prediksi dari nilai aktual, dalam satuan yang sama dengan target (juta Rupiah).
* Evaluasi pada Testing Set:
  * R2 Score: 0.7612: Pada data pengujian (data yang belum pernah dilihat model sebelumnya), R2 Score turun menjadi 0.7612 (76.12%). Ini menunjukkan bahwa model masih menjelaskan sebagian besar variabilitas, tetapi ada penurunan kinerja dibandingkan data pelatihan, yang bisa mengindikasikan sedikit overfitting.
  * MAE: 1921.5205 (juta Rp): MAE meningkat menjadi sekitar 1921.52 juta Rupiah pada data pengujian.
  * MSE: 11148025.6712: MSE juga meningkat pada data pengujian.
  * RMSE: 3338.8659 (juta Rp): RMSE meningkat menjadi sekitar 3338.87 juta Rupiah pada data pengujian.
  
Perbedaan antara metrik pelatihan dan pengujian mengkonfirmasi bahwa model memiliki sedikit overfitting pada data pelatihan, tetapi masih menunjukkan kinerja yang wajar pada data yang tidak terlihat.

10. Visualisasi Hasil Prediksi
"""

# Plot Prediksi vs Aktual untuk Testing Set
plt.figure(figsize=(10, 7))
plt.scatter(y_test, y_pred_test, alpha=0.6, edgecolors='k', c='royalblue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, label='Garis Ideal (Prediksi = Aktual)')
plt.xlabel('Harga Aktual (juta Rp)', fontsize=12)
plt.ylabel('Harga Prediksi (juta Rp)', fontsize=12)
plt.title('Harga Aktual vs. Prediksi Harga (Testing Set)', fontsize=14)
plt.legend()
plt.grid(True)
plt.show()

# Plot Residual
residuals = y_test - y_pred_test
plt.figure(figsize=(10, 7))
sns.histplot(residuals, kde=True, bins=20, color='seagreen')
plt.axvline(residuals.mean(), color='r', linestyle='dashed', linewidth=1.5, label=f'Mean Residual: {residuals.mean():.2f}')
plt.xlabel('Residual (Aktual - Prediksi) (juta Rp)', fontsize=12)
plt.ylabel('Frekuensi', fontsize=12)
plt.title('Distribusi Residual (Testing Set)', fontsize=14)
plt.legend()
plt.grid(True)
plt.show()

"""11. Pentingnya Fitur (Feature Importance)"""

if hasattr(best_xgboost_model, 'feature_importances_'):
    importances = best_xgboost_model.feature_importances_
    feature_names = X.columns
    feature_importance_df = pd.DataFrame({'Fitur': feature_names, 'Pentingnya': importances})
    feature_importance_df = feature_importance_df.sort_values(by='Pentingnya', ascending=False)

    plt.figure(figsize=(12, 8))
    sns.barplot(x='Pentingnya', y='Fitur', data=feature_importance_df, palette='viridis')
    plt.title('Pentingnya Fitur dari Model XGBoost Terbaik', fontsize=14)
    plt.xlabel('Pentingnya', fontsize=12)
    plt.ylabel('Fitur', fontsize=12)
    plt.grid(axis='x')
    plt.show()

    print("\nPentingnya Fitur (dari yang paling penting):")
    print(feature_importance_df)
else:
    print("\nModel terbaik tidak memiliki atribut 'feature_importances_'.")

"""* Pentingnya Fitur (dari yang paling penting):: Ini menunjukkan seberapa besar kontribusi setiap fitur terhadap prediksi model, diurutkan dari yang paling penting.
  * luas_bangunan_m2 (0.372223) adalah fitur paling penting, menunjukkan bahwa luas bangunan memiliki dampak terbesar pada harga rumah.
  * luas_tanah_m2 (0.286692) adalah fitur kedua paling penting.
  * Fitur-fitur lain seperti kamar_mandi, garasi_mobil, kamar_tidur, dan kategori_luas_tanah memiliki tingkat kepentingan yang lebih rendah tetapi tetap berkontribusi pada model.

12. DataFrame Prediksi Final
"""

prediksi_final_df = pd.DataFrame({
    'harga_aktual_juta': y_test.values,
    'harga_prediksi_juta': y_pred_test
})
prediksi_final_df['selisih_juta'] = prediksi_final_df['harga_aktual_juta'] - prediksi_final_df['harga_prediksi_juta']
prediksi_final_df['persentase_error'] = (np.abs(prediksi_final_df['selisih_juta']) / prediksi_final_df['harga_aktual_juta']) * 100

print("\nContoh Hasil Prediksi pada Data Test (dengan selisih dan % error):")
print(prediksi_final_df.head(10))

print("\nStatistik Deskriptif Persentase Error:")
print(prediksi_final_df['persentase_error'].describe())

print("\n--- Proses Selesai ---")

"""* Contoh Hasil Prediksi pada Data Test (dengan selisih dan % error):: Ini adalah tabel yang menunjukkan beberapa contoh hasil prediksi dari model pada data pengujian.
  * harga_aktual_juta: Harga rumah sebenarnya dalam juta Rupiah.
  * harga_prediksi_juta: Harga rumah yang diprediksi oleh model.
  * selisih_juta: Perbedaan antara harga aktual dan harga prediksi. Nilai negatif berarti model memprediksi lebih tinggi dari harga aktual.
  * persentase_error: Persentase kesalahan prediksi relatif terhadap harga aktual. Anda dapat melihat bahwa persentase error bervariasi secara signifikan antar sampel.
* Statistik Deskriptif Persentase Error:: Ini memberikan ringkasan statistik dari persentase error untuk semua sampel di data pengujian.
  * mean: Rata-rata persentase error adalah sekitar 26.80%.
  * std: Standar deviasi yang tinggi (27.03%) menunjukkan variasi yang besar dalam persentase error.
  * min: Error terendah sangat kecil (0.015%).
  * max: Error tertinggi mencapai 180.52%, menunjukkan bahwa ada beberapa prediksi yang sangat tidak akurat.
  * Kuartil (25%, 50%, 75%) memberikan gambaran tentang distribusi error. Misalnya, 50% prediksi memiliki error kurang dari 18.63%, tetapi 25% prediksi memiliki error lebih dari 37.11%.
"""